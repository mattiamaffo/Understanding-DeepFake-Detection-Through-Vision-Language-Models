{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12457166,"sourceType":"datasetVersion","datasetId":7858089},{"sourceId":12457216,"sourceType":"datasetVersion","datasetId":7858132},{"sourceId":12657249,"sourceType":"datasetVersion","datasetId":7998846},{"sourceId":12657280,"sourceType":"datasetVersion","datasetId":7998865},{"sourceId":12658472,"sourceType":"datasetVersion","datasetId":7999569},{"sourceId":12924296,"sourceType":"datasetVersion","datasetId":8178199},{"sourceId":12928267,"sourceType":"datasetVersion","datasetId":8180731},{"sourceId":12943779,"sourceType":"datasetVersion","datasetId":8191200}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers accelerate qwen-vl-utils bitsandbytes","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-06T07:51:59.998546Z","iopub.execute_input":"2025-08-06T07:51:59.998839Z","iopub.status.idle":"2025-08-06T07:53:47.801904Z","shell.execute_reply.started":"2025-08-06T07:51:59.998813Z","shell.execute_reply":"2025-08-06T07:53:47.801205Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\n\n# Percorso del file salvato\n# json_path = \"/kaggle/input/final-test-set/final_dataset.json\"\ndataset_path = '/kaggle/input/summarized-dataset/dataset_summarized'\n\n# Carica il dataset Hugging Face\n# hf_dataset = Dataset.from_json(json_path)\nhf_dataset = Dataset.load_from_disk(dataset_path)\n\n# Controlla un esempio\nprint(hf_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T07:54:16.130779Z","iopub.execute_input":"2025-08-06T07:54:16.131585Z","iopub.status.idle":"2025-08-06T07:54:17.811537Z","shell.execute_reply.started":"2025-08-06T07:54:16.131537Z","shell.execute_reply":"2025-08-06T07:54:17.810878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\n\n# Carica il classificatore zero-shot\nclassifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n\n# Etichette da prevedere\nimport re\n\nLABELS = [\"real\", \"fake\"]\n\ndef extract_label_from_response(response: str) -> int:\n    result = classifier(response, LABELS)\n    return LABELS.index(result[\"labels\"][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T07:54:20.440624Z","iopub.execute_input":"2025-08-06T07:54:20.441412Z","iopub.status.idle":"2025-08-06T07:54:52.369828Z","shell.execute_reply.started":"2025-08-06T07:54:20.441385Z","shell.execute_reply":"2025-08-06T07:54:52.368917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\nimport torch\nfrom PIL import Image\nfrom io import BytesIO\nimport os\n\nfrom transformers import AutoProcessor, AutoModelForVision2Seq\nfrom transformers.image_utils import load_image\nfrom transformers import BitsAndBytesConfig\n\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n\n# Few-shot esempi per real/fake\nFEW_SHOT_EXAMPLES = [\n    {\n        \"context\": \"A street photo taken at midday with perfectly natural shadows and realistic reflections on wet pavement.\",\n        \"label\": \"[Real]\",\n        \"motivation\": \"Consistent lighting and natural shadow falloff; reflections are coherent with the surfaces.\"\n    },\n    {\n        \"context\": \"An indoor scene where the textures on the walls appear overly smooth and uniform, and shadows lack realistic variation.\",\n        \"label\": \"[Fake]\",\n        \"motivation\": \"Uniform texture and flat shadows are typical AI generation artifacts.\"\n    },\n]\n\nSTATIC_PROMPTS = [\n    \"Analyze and classify [REAL] / [FAKE] the following image: <image>\",\n    \"Is the following image real or fake? <image>\\nChoose one: [Real] / [Fake].\",\n    \"Analyze and classify: [Real] / [Fake].\"\n]\n\nclass IdeficsTester:\n    def __init__(self, model_id=\"HuggingFaceM4/idefics2-8b-base\", device=\"cuda:0\"):\n        self.device = torch.device(device)\n        \n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_use_double_quant=True,\n            bnb_4bit_compute_dtype=torch.float16\n        )\n        \n        self.processor = AutoProcessor.from_pretrained(model_id)\n        self.model = AutoModelForVision2Seq.from_pretrained(\n            model_id,\n            torch_dtype=torch.float16,    \n            quantization_config=quantization_config,\n        ).to(self.device)\n\n    def build_prompt(self, prompt_type=\"dynamic\", x_t=\"\"):\n        few_shot = \"\".join(\n            f\"Example:\\nContext: {ex['context']}\\nAnswer: {ex['label']} Motivation: {ex['motivation']}\\n\\n\"\n            for ex in FEW_SHOT_EXAMPLES\n        )\n        if prompt_type == \"dynamic\" and x_t:\n            return (\n                f\"Based on the following image description and technical analysis, determine whether the image is real or fake. <image> \\n\\n\"\n                f\"Image Description and Technical Analysis:\\n{x_t.strip()}\\n\\n\"\n                \"Question: Is this image real or fake? Please provide a reasoned answer based on both the description and your analysis of the image. Answer with [Real] / [Fake].\\n\"\n                \"Answer:\"  # Il modello deve rispondere con [Real] o [Fake]\n            )\n        else:\n            idx = int(prompt_type.split(\"_\")[-1]) if \"_\" in prompt_type else 0\n            template = STATIC_PROMPTS[idx]\n            return f\"Question: {template}\\nAnswer:\"\n\n    def generate(self, image_path: str, prompt: str) -> str:\n        prompts = [\n          prompt\n        ]\n        images = [Image.open(image_path)]\n        inputs = self.processor(text=prompts, images=images, padding=True, return_tensors=\"pt\")\n        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n\n        generated_ids = self.model.generate(**inputs, max_new_tokens=6)\n        generated_texts = self.processor.batch_decode(generated_ids, skip_special_tokens=True)\n\n        return generated_texts[0].strip()\n\n    def extract_label(self, response: str) -> int:\n        return extract_label_from_response(response)\n\n    def test(self, example: dict, prompt_type=\"dynamic\"):\n        torch.cuda.empty_cache()\n        prompt = self.build_prompt(prompt_type, example.get(\"summarized_x_t\",\"\"))\n        resp = self.generate(example[\"image_k\"], prompt)\n        label = self.extract_label(resp)\n        return label, resp\n\n# wrapper\n_tester = IdeficsTester()\ndef test_idefics(example, prompt_type=\"dynamic\"):\n    return _tester.test(example, prompt_type)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T07:55:00.087723Z","iopub.execute_input":"2025-08-06T07:55:00.089123Z","iopub.status.idle":"2025-08-06T08:01:37.863495Z","shell.execute_reply.started":"2025-08-06T07:55:00.089084Z","shell.execute_reply":"2025-08-06T08:01:37.862930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_from_disk\nfrom tqdm import tqdm\nimport pandas as pd\n\ndef run_test():\n    #dataset = load_from_disk(DATASET_PATH)\n    #print(\"Dataset structure:\\n\", hf_dataset)\n    example = hf_dataset[3]\n    print(\"Ground_Truth:\\n\", example['label'])\n    #print(\"Image:\\n\", example['image'])\n    #print(\"Prompt:\\n\", example['x_t'])\n    label, response = test_idefics(example, \"dynamic\")\n    print(\"Output label:\\n\", label)\n    print(\"Output response:\\n\", response)\n\n#run_test()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-06T08:01:45.574774Z","iopub.execute_input":"2025-08-06T08:01:45.575073Z","iopub.status.idle":"2025-08-06T08:01:47.012378Z","shell.execute_reply.started":"2025-08-06T08:01:45.575050Z","shell.execute_reply":"2025-08-06T08:01:47.011125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom tqdm.auto import tqdm\nfrom datasets import load_from_disk\n\n# DATASET_PATH   = \"/kaggle/input/test-dataset-kaggle/test_dataset_kaggle\"\nCHECKPOINT_CSV = \"/kaggle/working/dynamic_new_dataset_sum_Idefics.csv\"\nPROMPT_TYPE    = \"dynamic\"\nCHECKPOINT_EVERY = 30  # salva ogni 30 campioni\n\n# 1) Carica dataset\n#dataset = load_from_disk(DATASET_PATH)\n\n# 2) Se esiste già un CSV di checkpoint, riloadalo e salta i campioni già processati\nif os.path.exists(CHECKPOINT_CSV):\n    df = pd.read_csv(CHECKPOINT_CSV)\n    processed_ids = set(df[\"img_id\"])\nelse:\n    df = pd.DataFrame(columns=[\"img_id\",\"gt_label\",\"pred_label\",\"response\"])\n    processed_ids = set()\n\n# 3) Loop con tqdm e checkpoint ogni N campioni\nfor sample in tqdm(hf_dataset, desc=f\"Eval {PROMPT_TYPE}\", dynamic_ncols=True):\n    img_id = sample[\"img_id\"]\n    if img_id in processed_ids:\n        continue\n\n    try:\n        pred_label, resp = test_idefics(sample, prompt_type=PROMPT_TYPE)\n    except Exception as e:\n        print(\"Errore nella generazione\")\n        pred_label, resp = -1, f\"[ERROR] {e}\"\n\n    # prepara la nuova riga\n    row = {\n        \"img_id\":     img_id,\n        \"gt_label\":   sample[\"label\"],\n        \"pred_label\": pred_label,\n        \"response\":   resp\n    }\n    # concatena in un colpo solo\n    df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n    processed_ids.add(img_id)\n\n    # salva checkpoint\n    if len(processed_ids) % CHECKPOINT_EVERY == 0:\n        df.to_csv(CHECKPOINT_CSV, index=False)\n\n# 4) Alla fine salva il CSV definitivo\ndf.to_csv(CHECKPOINT_CSV, index=False)\nprint(\"✅ Checkpoint salvato in:\", CHECKPOINT_CSV)\n\n# 5) Calcolo accuracy su quelli validi\nvalid = df[\"pred_label\"] != -1\nacc = (df.loc[valid, \"gt_label\"] == df.loc[valid, \"pred_label\"]).mean()\nprint(f\"Accuracy {PROMPT_TYPE}: {acc:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}